# Neural Network
* Before: Linear score function
* Now: 2-layer(multi layer) Neural Network 
    * ex> W2 * max(0,W1 * x) => learned featured(not Hand-crafted feature)
    * feuture를 learning한다=> 층을 쌓는다
    * max로 묶은 이유 => W1*W2*x => 그냥 하나의 linear function이 된다
        * 그래서 non-linear 한 함수로 linear관계를 깨서 층을 분할하는 역할을 해준다
            * 즉 max= 활성화 함수(ex> ReLU)
                * but 층이 깊어질수록 cpapacity가 증가한다
