# Linear Regression
23p(linear regression)
# Vectorization
27p
GPU를 주로 사용하는 딥러닝은 병렬처리에 유용하기 때문에 벡터화한다-> for문 x
29p
30p
미분학 관점에서 미분값0인 점 찾기
-> 근데 다인자이므로 편미분을 해야한다
31p
모든 j(feature)에서 0이어야 한다
모든 W에서 gradient가 0인 점 찾기?
32p
어떤 공식을 사용하면 최적의W를 찾을 수 있다
36p
feature: raw data(주어진 데이터, 35p 파란점)
파이(x)=> x를 featurising=> feature mapping
ex> 37p 원래 x는 1차원 데이터였는데 x가 파이라는 function을 걸쳐 x^2형태로 바뀜
=>fB(x)=B1x+B2x^2
38p
최적의 파라미터 B

40p
feature의 종류
1. 다항식
2. 절편
3. 수로표현x인 것을 숫자로 표현(1=좋다,0=안좋다..)

=>but feature를 늘리면 오버피팅될 가능성이 높다
즉 모델과 파라미터, feature의 선택은 경험을 통해 적합한 개수를 선정해야한다

46p
overfitting vs underfitting
underfitting 시 feature를 늘러야한다

47p 
overfitting 이 일어나는 이유

정규화(규제)=> 오버피팅 방지
underfitting
54p
capacity: 모델의 크기
variance: 변동(모델값이 변하는 정도)
bias: 편차(목적값에 벗어나있는 정도)