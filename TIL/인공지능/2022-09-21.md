## 학습모델선택
파라미터= 매개변수
하이퍼파라미터= 사용자가 설정하는 매개변수
이론적 
* 검증 데이터 집합 이용
    training
    (검증 데이터)validation(학습에 이용x)
    testing(학습에 이용x)
* 교차 검증 데이터집합 이용
    데이터 수집의 한계로 별도의 검증 데이터집합이 없는 상황(부족한 데이터)
    데이터를 그룹으로 분할해서 각그룹이 번갈아 가면서 검증 데이터 그룹이 된다.
    계속해서 검증 데이터 그룹이 바뀌면서 성능을 체크한 후 평균값

    학습 모델 선택의 한계와 현실적 해결 전략
        충분히 큰 용량의 학습 모델 선택
        (오버피팅이 일어나지 않도록 규제를 적용)
# 규제
규제를 통해서 일반화 성능 보장 Eout=Ein
## 규제의 종류
* 데이터 증대
    훈련집합의 크기 증가
    데이터 라벨링은 힘들기 때문에 인위적으로 데이터를 증대한다
        ex> 약간의 회전, 왜곡, 이동
            => 데이터의 고유 특징이 변하지 않도록 주의

* 가중치 벌칙
    자유도에 제한을 둔다
        원래 파라미터를 줄인다
        오차=본래 훈련집합의 오차 && 자신의 크기
            => 오차를 줄이기 위해 자신의 크기를 줄인다(파라미터가 줄어든다.)

* 드롭 아웃
    불필요한 커넥션 제거= 매개변수의 제한
* 조기 멈춤
    오버피팅 되기전에 학습을 중단한다= 학습의 제한

# 선형대수

기계학습에서 수학의 역할
- 확률 및 통계 가정을 통한 데이터 수집
- 선형대수를 통한 데이터 특징 공간과 가설의 역할
- 학습 과업에 적합한 목적함수 정의
- 목적함수가 최소값이 되는 최적점을 찾아주는 최적화

## 선형대수
* 데이터 분석에 필요한 배경 이해를 제공
* 연산 장치는 데이터 분석을 위해 데이터를 숫자로 구성된 형태(수, 벡터, 행렬, 텐서)로 이해
* 데이터 특징 공간과 차원을 표현 및 변환
* 선형대수를 활용하여 데이터를 포함한 학습 연산 과정을 간단한 수식으로 서술
즉 데이터의 특징이 뚜럿한 배경을 만들때도, 이를 표현할 때도 선형대수가 필요

### 벡터
* 벡터를 이루는 데이터 개수가 n개면 n차원 벡터라고 한다
* 벡터의 두가지 요소= 크기(놈,길이)와 방향
### 행렬
* 여러개의 벡터를 담음
* 데이터들을 표현하는 방식
* ex> col 하나하나가 특징, 각각의 row는 sample
#### 전치행렬
행의 요소와 열의 요소 전치
* 성질
1. (A^T)^T=A
2. (A+B)^T=A^T+B^T
3. (AB)^T=B^T*A^T
4. (kA)^T=kA^T
#### 벡터간 거리
* 유클리드 거리
    * 2차 놈: L2 distance
* 맨해튼 거리
    * 1차 놈: L1 distance
* 코사인 거리
