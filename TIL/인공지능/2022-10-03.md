# 확률 및 통계
* 확률실험 29p
* 확률규칙
    * `조건부 확률`
        * 독립사건
        * 종속사건
        * Joint Probability(결합확률)
    * `확률의 연쇄법칙`
        * NLP
* 빈도 확률
    * 모든 것은 실험으로만 알 수 있다
    * 여러 번 반복 실험으로 얻은 객관적인 정보다
* 베이지안 확률
    * 실험하지 않아도 주어진 정보들을 이용해서 확률적으로 표현될 수 있다

### `베이즈 정리`
* 일어나지 않았거나 불확실한 사건에 대한 베이지안 확률을 구함
    1. 주관적인 가설의 사전 확률을 정하고
    2. 관찰된 데이터를 기반으로 가능도를 계산해서
    3. 처음 설정한 주관적 확률을 보정함
* 기계학습에서 필요한 이유:
    * Iris 데이터 분류 과업
        * 특징 벡터 x, 부류 y

#### 확률과 우도
* 확률 : 확률 분포가 있을 때, 관찰값 또는 관측 구간이 분포 안에 어떤 확률을 보여줌
* 우도(가능도) : 주어진 특정 관찰값을 기반으로 특정 확률 분포에서 어떤 확률로 나타날 가능성을 말함

### 최대 우도 추정
log 이유 곱셈을 덧셈으로 바꾸기 위해서 => 계산의 용이성

### 통계
* 통계적 대표값
    * 평균
    * 분산
        * 평균에서 얼마만큼 떨어져있는가
        * 공분산 행렬(벡터의 요소마다의 상관관계를 알아내는 방법)

* 확률 분포 유형
    * 혼합 분포?
        * 43p
            * 빨간색을 표현하기 위해 3개의 가우시안 분포(파란색)으로 표현
            * 파이: 전체 확률이 1이 되야하므로 각각의 가우시안에 가중치
            * EM 알고리즘
* 확룰 변수 변환
    * 가역성